# N-Gram Language Model â€“ Next Word Prediction  
A simple and beginner-friendly implementation of an **N-Gram Based Next-Word Prediction Model** built using Python.  
This project uses statistical NLP methods (no deep learning) to predict the next word based on previous context.

---

## ğŸ“Œ Features
- Tokenization & preprocessing  
- Unigram, Bigram, Trigram generation  
- Probability & smoothing  
- Next-word prediction  
- Works on any custom text dataset  
- Clean & easy-to-understand code  

---

## ğŸ“‚ Project Structure

	Ngram-Model/
		â”‚â”€â”€ flowchart.png
		â”‚â”€â”€ ngram-language-model.py
		â”‚â”€â”€ training_sentences.txt

---

## ğŸ§  How the Model Works (Simple Explanation)

1. **Text Cleaning**  
   Input text is converted to lowercase and split into tokens.

2. **Create N-Grams**  
   Model generates:
   - 1-grams (single word)
   - 2-grams (pairs)
   - 3-grams (triplets)

3. **Count Frequencies**  
   - Each n-gram is counted to build probability tables.

4. **Predict Next Word**  
   - For a given context sentence, the model finds the most probable next word.

---

## ğŸ”„ Project Flowchart

   - Below is the visual flow of how the prediction system works:

![Flowchart](flowchart.png)

---

## ğŸ“œ Code Overview

### ğŸ”§ Training the Model
```python
lm = NgramLM(n=3, alpha=0.5)
lm.fit(corpus)
ctx = tokenize("The weather changed")
lm.predict_next(ctx, top_k=3)
```
## ğŸ“¤ Example Output

==================== N-GRAM NEXT WORD PREDICTION ====================

ğŸ”¹ Input Context:
   ['the', 'weather', 'changed']

ğŸ”¹ Top 3 Predicted Suggestions:
   1. suddenly     | Probability: 0.1842
   2. today        | Probability: 0.1219
   3. after        | Probability: 0.0973

====================================================================

## ğŸ“Š Dataset

### The model uses a small training dataset stored in:
   - training_sentences.txt

## ğŸ› ï¸ Technologies Used

   -  Python
   - 
   -  Regex
   - 
   -  Collections (Counter, defaultdict)
   - 
   -  Math (log & exp for probability)

## ğŸš€ How to Run

### Clone the repo

   #### git clone https://github.com/Golu09846/ngram-language-model/blob/main/ngram-language-model.py


### Navigate to folder

   - cd Ngram-Model


### Run the model

   - python ngram-language-model.py

## ğŸ™Œ Author

### Abdullah
### Data Science Intern @ AnalyticShala
### Trainer: Faizan Ansari

## â­ Contribute

### Pull requests and improvements are welcome!
## ğŸ“„ License

### This project is open-source under the MIT License.
